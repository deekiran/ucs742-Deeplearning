{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "ee128c1a-3e04-4029-b75c-81414f3b2411",
        "_uuid": "548696bc2b35980d59447492991f766c5c6dbb73"
      },
      "cell_type": "markdown",
      "source": "<!--NAVIGATION-->"
    },
    {
      "metadata": {
        "_cell_guid": "99001eca-7b0c-4c88-ac3d-490b047b1bfe",
        "_uuid": "193856427f94bfab649b48c9e3bdbe38ad5b2cec"
      },
      "cell_type": "markdown",
      "source": "# An Interactive Character-Level Language Model tensorflow implentaion using LSTM.\n\nhttps://theblog.github.io/post/character-language-model-lstm-tensorflow/"
    },
    {
      "metadata": {
        "_cell_guid": "1fea9fea-cc06-4f90-b052-f54680f2873b",
        "_uuid": "94843d89849288a5a3d2e2e3e5bb437374af6b72"
      },
      "cell_type": "markdown",
      "source": "This script is written in python and was run in kaggle kernel.\n"
    },
    {
      "metadata": {
        "_cell_guid": "96cd6f43-6d33-4427-8225-4bfc9bf19791",
        "_uuid": "b16efc9391099d5c220f021b49aea3ee018981b6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorlm import CharLM\nfrom tensorlm import Vocabulary, Dataset, GeneratingLSTM\nimport numpy as np\ntf.reset_default_graph()\nwith tf.Session() as session:\n    \n    # Create a new model. You can also use WordLM\n    model = CharLM(session, \"../input/sherly/tinytrain.txt\", max_vocab_size=96,\n                   neurons_per_layer=100, num_layers=3, num_timesteps=15)\n    \n    # Train it \n    model.train(session, max_epochs=10, max_steps=500)\n    \n    # Let it generate a text\n    generated = model.sample(session, \"The \", num_steps=100)\n    print(\"The \" + generated)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1805537882861d57e02c42053f77e594530c3f28"
      },
      "cell_type": "code",
      "source": "from tensorlm import Vocabulary, Dataset, GeneratingLSTM\ntf.reset_default_graph()\n\nbatch_inputs = np.array([[1, 2, 3, 4], [15, 16, 17, 18]])  # 2 batches, 4 time steps each\nbatch_targets = np.array([[2, 3, 4, 5], [16, 17, 18, 19]])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "228ac3b756e922aa76f5949810c8a9fa0d021474"
      },
      "cell_type": "code",
      "source": "model = GeneratingLSTM(vocab_size=20, neurons_per_layer=10, num_layers=2, max_batch_size=2)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "799633fc28fd5a9a7702c4b3345e8b9bcead68a8"
      },
      "cell_type": "code",
      "source": "#session.run(tf.global_variables_initializer())\n#tf.Graph.graph_def_versions\nBATCH_SIZE = 20\nNUM_TIMESTEPS = 15\nwith tf.Session() as session:\n    session.run(tf.global_variables_initializer())\n    for _ in range(5000):\n        model.train_step(session, batch_inputs, batch_targets)\n    sampled = model.sample_ids(session, [15], num_steps=3)\n    print(\"Sampled: \" + str(sampled))\n        # Generate a token -> id vocabulary based on the text\n    vocab = Vocabulary.create_from_text(\"../input/sherly/tinytrain.txt\", max_vocab_size=96,\n                                        level=\"char\")\n    print(len(vocab))\n    # Obtain input and target batches from the text file\n    dataset = Dataset(\"../input/sherly/tinytrain.txt\", vocab, BATCH_SIZE, NUM_TIMESTEPS)\n    print(len(dataset))\n#-----error\n    \n    # Create the model in a TensorFlow graph\n    model = GeneratingLSTM(vocab_size=62, neurons_per_layer=100, num_layers=2,\n                          max_batch_size=BATCH_SIZE, output_keep_prob=0.5)\n    model = GeneratingLSTM(vocab_size=vocab.get_size(), neurons_per_layer=100, num_layers=2,\n                           max_batch_size=BATCH_SIZE, output_keep_prob=0.5)\n\n    # Initialize all defined TF Variables\n    session.run(tf.global_variables_initializer())\n\n    # Do the training\n    epoch = 1\n    step = 1\n    for epoch in range(20):\n        for inputs, targets in dataset:\n            loss = model.train_step(session, inputs, targets)\n\n            if step % 100 == 0:\n                # Evaluate from time to time\n                dev_dataset = Dataset(\"../input/sherlo/tinyvalid.txt\", vocab,\n                                      batch_size=BATCH_SIZE, num_timesteps=NUM_TIMESTEPS)\n                dev_loss = model.evaluate(session, dev_dataset)\n                print(\"Epoch: %d, Step: %d, Train Loss: %f, Dev Loss: %f\" % (\n                    epoch, step, loss, dev_loss))\n\n                # Sample from the model from time to time\n                print(\"Sampled: \\\"The \" + model.sample_text(session, vocab, \"The \") + \"\\\"\")\n\n            step += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c45b80b0344742490e4a68e5eda5e655db53f386"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}