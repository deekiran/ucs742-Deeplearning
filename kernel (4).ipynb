{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "ee128c1a-3e04-4029-b75c-81414f3b2411",
        "_uuid": "548696bc2b35980d59447492991f766c5c6dbb73"
      },
      "cell_type": "markdown",
      "source": "<!--NAVIGATION-->"
    },
    {
      "metadata": {
        "_cell_guid": "99001eca-7b0c-4c88-ac3d-490b047b1bfe",
        "_uuid": "193856427f94bfab649b48c9e3bdbe38ad5b2cec"
      },
      "cell_type": "markdown",
      "source": "# MNIST Handwritten characters classifier"
    },
    {
      "metadata": {
        "_cell_guid": "1fea9fea-cc06-4f90-b052-f54680f2873b",
        "_uuid": "94843d89849288a5a3d2e2e3e5bb437374af6b72"
      },
      "cell_type": "markdown",
      "source": "This script is written in python and was run in kaggle kernel.\n"
    },
    {
      "metadata": {
        "_cell_guid": "77c7c647-f140-4bc8-8793-edaf2814955e",
        "_uuid": "c362d6cfa0fdc61746ae3559f69dc8fdb1d501ee"
      },
      "cell_type": "markdown",
      "source": "### The Python Interpreter\n```\n$ python\nPython 3.5.1 |Continuum Analytics, Inc.| (default, Dec  7 2015, 11:24:55)\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>>\n```\nWith the interpreter running, you can begin to type and execute code snippets.\nHere we'll use the interpreter as a simple calculator, performing calculations and assigning values to variables:\n``` python\n>>> 1 + 1\n2\n>>> x = 5\n>>> x * 3\n15\n```\n\nThe interpreter makes it very convenient to try out small snippets of Python code and to experiment with short sequences of operations."
    },
    {
      "metadata": {
        "_cell_guid": "cd0fbb1d-5dfd-42aa-9611-e01816c021d2",
        "_uuid": "fa1c3daf08dd755705ffad9ffa3beadda0d4be94"
      },
      "cell_type": "markdown",
      "source": "### Convulational Neural Network\nThis time we define a large CNN architecture with additional convolutional, max pooling layers and fully connected layers. The network topology can be summarized as follows.\n\nConvolutional layer with 30 feature maps of size 5×5.\nPooling layer taking the max over 2*2 patches.\nConvolutional layer with 15 feature maps of size 3×3.\nPooling layer taking the max over 2*2 patches.\nDropout layer with a probability of 20%.\nFlatten layer.\nFully connected layer with 128 neurons and rectifier activation.\nFully connected layer with 50 neurons and rectifier activation.\nOutput layer.\n\n"
    },
    {
      "metadata": {
        "_cell_guid": "96cd6f43-6d33-4427-8225-4bfc9bf19791",
        "_uuid": "b16efc9391099d5c220f021b49aea3ee018981b6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Plot ad hoc mnist instances\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\n\nK.set_image_dim_ordering('th')\nseed = 7\nnp.random.seed(seed)\n",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "1d94e4de3fae07d6dfaab7db4d2e955479b9224e"
      },
      "cell_type": "code",
      "source": "# load (downloaded if needed) the MNIST dataset\nmnist =np.load('../input/mnist.npz')\nX_train = mnist['x_train.npy']\ny_train =mnist['y_train.npy']\nX_test =mnist['x_test.npy']\ny_test =mnist['y_test.npy']\n# reshape to be [samples][pixels][width][height]\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe24bcaae6bc116f762bffd2c1040ce6e8c7d1cf"
      },
      "cell_type": "code",
      "source": "# normalize inputs from 0-255 to 0-1\nX_train = X_train / 255\nX_test = X_test / 255\n# one hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\n",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2987d01da82c7e73e73b4a0f71fc1121ba575eb"
      },
      "cell_type": "code",
      "source": "# define the larger model\n# create model\nmodel = Sequential()\nmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(15, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n# Compile model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#return model\n# build the model\n# Fit the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 4s 75us/step - loss: 0.3904 - acc: 0.8803 - val_loss: 0.0890 - val_acc: 0.9716\nEpoch 2/10\n60000/60000 [==============================] - 3s 54us/step - loss: 0.1003 - acc: 0.9699 - val_loss: 0.0552 - val_acc: 0.9821\nEpoch 3/10\n60000/60000 [==============================] - 3s 53us/step - loss: 0.0741 - acc: 0.9773 - val_loss: 0.0439 - val_acc: 0.9858\nEpoch 4/10\n60000/60000 [==============================] - 3s 55us/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.0356 - val_acc: 0.9877\nEpoch 5/10\n60000/60000 [==============================] - 3s 54us/step - loss: 0.0518 - acc: 0.9839 - val_loss: 0.0336 - val_acc: 0.9890\nEpoch 6/10\n60000/60000 [==============================] - 3s 53us/step - loss: 0.0444 - acc: 0.9857 - val_loss: 0.0278 - val_acc: 0.9905\nEpoch 7/10\n60000/60000 [==============================] - 3s 53us/step - loss: 0.0393 - acc: 0.9879 - val_loss: 0.0307 - val_acc: 0.9896\nEpoch 8/10\n60000/60000 [==============================] - 3s 53us/step - loss: 0.0358 - acc: 0.9887 - val_loss: 0.0259 - val_acc: 0.9910\nEpoch 9/10\n60000/60000 [==============================] - 3s 52us/step - loss: 0.0332 - acc: 0.9895 - val_loss: 0.0245 - val_acc: 0.9924\nEpoch 10/10\n60000/60000 [==============================] - 3s 52us/step - loss: 0.0307 - acc: 0.9903 - val_loss: 0.0273 - val_acc: 0.9914\nLarge CNN Error: 0.86%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70b28f07ce8b432a09d4b5c95e189be9a46a0a59"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_kg_hide-output": false,
        "trusted": true,
        "scrolled": false,
        "_uuid": "49534f8e12ee4cce36f6d3d599c9fae06f5b95a9"
      },
      "cell_type": "code",
      "source": "\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef5bbe70b2fabd1bf5461ba8056696034227cf02"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a229306039e8f1f85d7dd68f8eb80d2f5be65468"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}